{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2854 1899\n",
      "['alt.atheism', 'comp.graphics', 'rec.sport.baseball', 'sci.med', 'soc.religion.christian']\n"
     ]
    }
   ],
   "source": [
    "# 认识20newsgroups数据集\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "# dataset=fetch_20newsgroups(subset='all') \n",
    "# 自动下载第二个版本20news-bydate.tar.gz\n",
    "# print(len(dataset.data)) # dataset_X 的样本数\n",
    "# print(dataset.target_names) # dataset_y的名称，标签名称\n",
    "\n",
    "# train_set=fetch_20newsgroups(subset='train') # 仅仅提取中间的train set\n",
    "# test_set=fetch_20newsgroups(subset='test')\n",
    "\n",
    "# 如果仅仅需要其中的某几个类别，可以用\n",
    "sample_cate = ['alt.atheism', 'soc.religion.christian',\n",
    "               'comp.graphics', 'sci.med', 'rec.sport.baseball'] # 只取5个类别\n",
    "train_set = fetch_20newsgroups(subset='train',categories=sample_cate,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove = ('headers', 'footers', 'quotes'))\n",
    "test_set = fetch_20newsgroups(subset='test', categories=sample_cate,\n",
    "                              shuffle=True, random_state=42,\n",
    "                              remove = ('headers', 'footers', 'quotes'))\n",
    "print(len(train_set.data), len(test_set.data)) # 2854 1899\n",
    "print(train_set.target_names) # 只有五个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sample num:  2968\n",
      "['misc.forsale', 'rec.motorcycles', 'rec.sport.baseball', 'sci.crypt', 'sci.space']\n",
      "test sample num:  1975\n"
     ]
    }
   ],
   "source": [
    "# 1, 准备数据集\n",
    "category_map = {'misc.forsale': 'Sales', 'rec.motorcycles': 'Motorcycles', \n",
    "        'rec.sport.baseball': 'Baseball', 'sci.crypt': 'Cryptography', \n",
    "        'sci.space': 'Space'}\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "train_set=fetch_20newsgroups(subset='train',categories=category_map.keys(),\n",
    "                             shuffle=True,random_state=42,\n",
    "                            remove = ('headers', 'footers', 'quotes'))\n",
    "test_set=fetch_20newsgroups(subset='test',categories=category_map.keys(),\n",
    "                             shuffle=True,random_state=42,\n",
    "                           remove = ('headers', 'footers', 'quotes'))\n",
    "# 获取到的train_set包含有2968个样本，\n",
    "print('train sample num: ', len(train_set.data)) # 2968\n",
    "print(train_set.target_names) # 确保是我们要提取的这五个类别\n",
    "\n",
    "print('test sample num: ', len(test_set.data)) # 1975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2968, 31206)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english',lowercase=True)\n",
    "train_vector = vectorizer.fit_transform(train_set.data)\n",
    "print(train_vector.shape) # (2968, 31206)\n",
    "# 此处相当于有2968个词袋，对这些词袋进行TfidfVectorizer进行特征提取，\n",
    "# 得到最具典型的一些单词，这些单词的个数有31206个，故而得到(2968, 30206)矩阵\n",
    "# 矩阵中的元素表示这个单词在该词袋中出现的tf-idf权重，值越大，表示该单词越重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义模型，训练特征\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier=MultinomialNB(alpha=.01, fit_prior = False)\n",
    "classifier.fit(train_vector,train_set.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1975, 31206)\n",
      "test set F1 score:  0.8774683544303797\n"
     ]
    }
   ],
   "source": [
    "# 查看这个数据集在test_set上的表现\n",
    "from sklearn import metrics\n",
    "test_vector=vectorizer.transform(test_set.data)\n",
    "print(test_vector.shape)\n",
    "pred=classifier.predict(test_vector)\n",
    "F1_score=metrics.f1_score(test_set.target, pred, average='micro')\n",
    "print('test set F1 score: ',F1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best param_set found on train set: {'alpha': 0.05, 'fit_prior': True}\n",
      "Detailed classification report on test set:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.89      0.91       390\n",
      "          1       0.80      0.91      0.85       398\n",
      "          2       0.93      0.88      0.91       397\n",
      "          3       0.90      0.88      0.89       396\n",
      "          4       0.91      0.88      0.89       394\n",
      "\n",
      "avg / total       0.89      0.89      0.89      1975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 用GridSearchCV优化参数\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "parameters = {'fit_prior':(True, False), 'alpha':(0.01,0.05,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0)}\n",
    "clf = GridSearchCV(classifier,parameters,cv=5,scoring='precision_macro',n_jobs=-1)\n",
    "clf.fit(train_vector, train_set.target)\n",
    "print(\"Best param_set found on train set: {}\".format(clf.best_params_))\n",
    "\n",
    "print(\"Detailed classification report on test set:\")\n",
    "y_true, y_pred = test_set.target, clf.predict(test_vector)\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

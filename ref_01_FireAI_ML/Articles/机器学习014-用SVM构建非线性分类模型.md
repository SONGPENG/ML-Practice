【火炉炼AI】机器学习014-用SVM构建非线性分类模型
-

(本文所使用的Python库和版本号: Python 3.5, Numpy 1.14, scikit-learn 0.19, matplotlib 2.2 )

支持向量机（Support Vector Machine，SVM）是一种常见的判别方法，其基本模型是在特征空间上找到最佳的分离超平面，使得数据集上的正负样本间隔最大。SVM用来解决二分类问题的有监督学习算法，其可以解决线性问题，也可以通过引入核函数的方法来解决非线性问题。

本项目旨在使用SVM构建非线性分类模型来判别数据集的不同类别。

<br/>

## 1. 准备数据集

首先来加载和查看数据集的一些特性。如下代码加载数据集并查看其基本信息

```Python
# 准备数据集
data_path='E:\PyProjects\DataSet\FireAI/data_multivar_2_class.txt'
df=pd.read_csv(data_path,header=None)
# print(df.head()) # 没有问题
print(df.info()) # 查看数据信息，确保没有错误
dataset_X,dataset_y=df.iloc[:,:-1],df.iloc[:,-1]
# print(dataset_X.head())
# print(dataset_X.info())
# print(dataset_y.head()) # 检查没问题
dataset_X=dataset_X.values
dataset_y=dataset_y.values
```

**-------------------------------------输---------出--------------------------------**

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 300 entries, 0 to 299
Data columns (total 3 columns):
0    300 non-null float64
1    300 non-null float64
2    300 non-null int64
dtypes: float64(2), int64(1)
memory usage: 7.1 KB
None

**--------------------------------------------完-------------------------------------**

从上面的df.info()函数的结果可以看出，这个数据集有两个特征属性（0,1列，连续的float类型），一个标记（2列，离散的int型，只有两个类别），每一列都没有缺失值。然后来看看这个数据集中数据点的分布情况，如下图所示：

```Python
# 数据集可视化
def visual_2D_dataset(dataset_X,dataset_y):
    '''将二维数据集dataset_X和对应的类别dataset_y显示在散点图中'''
    assert dataset_X.shape[1]==2,'only support dataset with 2 features'
    plt.figure()
    classes=list(set(dataset_y)) 
    markers=['.',',','o','v','^','<','>','1','2','3','4','8'
             ,'s','p','*','h','H','+','x','D','d','|']
    colors=['b','c','g','k','m','w','r','y']
    for class_id in classes:
        one_class=np.array([feature for (feature,label) in 
                   zip(dataset_X,dataset_y) if label==class_id])
        plt.scatter(one_class[:,0],one_class[:,1],marker=np.random.choice(markers,1)[0],
                    c=np.random.choice(colors,1)[0],label='class_'+str(class_id))
    plt.legend()
    
visual_2D_dataset(dataset_X,dataset_y)
```

![数据集中数据点的分布情况](https://i.imgur.com/VjEhMkC.png)

我以前的很多文章都讲到了数据集的处理，拆分，准备等，此处的数据集比较简单，故而简单讲述一下。

<br/>

## 2. 用SVM构建线性分类器

你没有看错，我就是想用SVM构建一个线性分类器来判别这个数据集。当然，即使是入门级的机器学习攻城狮们，也能看出，这个数据集是一个线性不可分类型，需要用非线性分类器来解决。所以，此处，我就用线性分类器来拟合一下，看看会有什么样的“不好”的结果。

```Python
# 从数据集的分布就可以看出，这个数据集不可能用直线分开
# 为了验证我们的判断，下面还是使用SVM来构建线性分类器将其分类

# 将整个数据集划分为train set和test set
from sklearn.model_selection import train_test_split
train_X, test_X, train_y, test_y=train_test_split(
    dataset_X,dataset_y,test_size=0.25,random_state=42)

# print(train_X.shape)  # (225, 2)
# print(train_y.shape)  # (225,)
# print(test_X.shape)  # (75, 2)

# 使用线性核函数初始化一个SVM对象。
from sklearn.svm import SVC
classifier=SVC(kernel='linear') # 构建线性分类器
classifier.fit(train_X,train_y)
```

**-------------------------------------输---------出--------------------------------**

SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)

**--------------------------------------------完-------------------------------------**

然后查看一下这个训练好的SVM线性分类器在训练集和测试集上的表现，如下为在训练集上的性能报告：

```Python
# 模型在训练集上的性能报告：
from sklearn.metrics import classification_report
plot_classifier(classifier,train_X,train_y)  # 分类器在训练集上的分类效果
target_names = ['Class-0', 'Class-1']
y_pred=classifier.predict(train_X)
print(classification_report(train_y, y_pred, target_names=target_names))
```

![SVM线性分类器在训练集上的分类效果](https://i.imgur.com/gaE3rZi.png)

**-------------------------------------输---------出--------------------------------**

precision    recall  f1-score   support

Class-0       0.60      0.96      0.74       114
Class-1       0.89      0.35      0.50       111

avg / total       0.74      0.66      0.62       225

**--------------------------------------------完-------------------------------------**

很明显，从分类效果图和性能报告中，都可以看出这个模型很差，差到姥姥家了。。。
所以，更不用说，在测试集上的表现了，当然是一个差字了得。。。

```Python
# 分类器在测试集上的分类效果
plot_classifier(classifier,test_X,test_y)  

target_names = ['Class-0', 'Class-1']
y_pred=classifier.predict(test_X)
print(classification_report(test_y, y_pred, target_names=target_names))
```

![SVM线性分类器在测试集上的分类效果](https://i.imgur.com/vwm0B18.png)

**-------------------------------------输---------出--------------------------------**

precision    recall  f1-score   support

Class-0       0.57      1.00      0.73        36
Class-1       1.00      0.31      0.47        39

avg / total       0.79      0.64      0.59        75

**--------------------------------------------完-------------------------------------**


<br/>

## 3. 用SVM构建非线性分类器

很明显，用线性分类器解决不了这个数据集的判别问题，所以我们就上马非线性分类器吧。

使用SVM构建非线性分类器主要是考虑使用不同的核函数，此处指讲述两种核函数：多项式核函数和径向基函数。

```Python
# 从上面的性能报告中可以看出，分类效果并不好
# 故而我们使用SVM建立非线性分类器，看看其分类效果
# 使用SVM建立非线性分类器主要是使用不同的核函数
# 第一种：使用多项式核函数：
classifier_poly=SVC(kernel='poly',degree=3) # 三次多项式方程
classifier_poly.fit(train_X,train_y)

# 在训练集上的表现为：
plot_classifier(classifier_poly,train_X,train_y)  

target_names = ['Class-0', 'Class-1']
y_pred=classifier_poly.predict(train_X)
print(classification_report(train_y, y_pred, target_names=target_names))
```

![SVM多项式核函数的非线性分类器的分类效果](https://i.imgur.com/ZZhCO4e.png)

**-------------------------------------输---------出--------------------------------**

precision    recall  f1-score   support

Class-0       0.92      0.85      0.89       114
Class-1       0.86      0.93      0.89       111

avg / total       0.89      0.89      0.89       225

**--------------------------------------------完-------------------------------------**

```Python
# 第二种：使用径向基函数建立非线性分类器
classifier_rbf=SVC(kernel='rbf') 
classifier_rbf.fit(train_X,train_y)

# 在训练集上的表现为：
plot_classifier(classifier_rbf,train_X,train_y)  

target_names = ['Class-0', 'Class-1']
y_pred=classifier_rbf.predict(train_X)
print(classification_report(train_y, y_pred, target_names=target_names))
```

![SVM径向基函数的非线性分类器的分类效果](https://i.imgur.com/Bjk6NSv.png)

**-------------------------------------输---------出--------------------------------**

precision    recall  f1-score   support

Class-0       0.96      0.96      0.96       114
Class-1       0.96      0.95      0.96       111

avg / total       0.96      0.96      0.96       225

**--------------------------------------------完-------------------------------------**


**\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#小\*\*\*\*\*\*\*\*\*\*结\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#**

**1. 用SVM构建非线性分类器很简单，只要使用不同的核函数就可以。**

**2. 对于这个数据集而言，使用了非线性分类器之后，分类效果得到了极大的改善，这个可以从性能报告中看出，而且，很明显两种非线性核函数，径向基函数rbf的分类效果要比多项式核函数的效果更好一些。**

**3. 这个模型也许还可以继续优化一些超参数，从而得到更好的分类效果。**

**\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#**



<br/>

注：本部分代码已经全部上传到（[**我的github**](https://github.com/RayDean/MachineLearning)）上，欢迎下载。

参考资料:

1, Python机器学习经典实例，Prateek Joshi著，陶俊杰，陈小莉译
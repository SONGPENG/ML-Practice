{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(37) # 使得每次运行得到的随机数都一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "import cv2,itertools,pickle,os\n",
    "from cv2 import xfeatures2d\n",
    "from glob import glob\n",
    "\n",
    "class DataSet:\n",
    "    \n",
    "    def __init__(self,img_folder,cluster_model_path,img_ext='jpg',max_samples=12,clusters_num=32):\n",
    "        self.img_folder=img_folder\n",
    "        self.cluster_model_path=cluster_model_path\n",
    "        self.img_ext=img_ext\n",
    "        self.max_samples=max_samples\n",
    "        self.clusters_num=clusters_num\n",
    "        self.img_paths=self.__get_img_paths()\n",
    "        self.all_img_paths=[list(item.values())[0] for item in self.img_paths]\n",
    "        self.cluster_model=self.__load_cluster_model()\n",
    "            \n",
    "    def __get_img_paths(self):\n",
    "        folders=glob(self.img_folder+'/*-*') # 由于图片文件夹的名称是数字+‘-’开头，故而可以用这个来获取\n",
    "        img_paths=[]\n",
    "        for folder in folders:\n",
    "            class_label=folder.split('\\\\')[-1]\n",
    "            img_paths.append({class_label:glob(folder+'/*.'+self.img_ext)}) \n",
    "            # 每一个元素都是一个dict，key为文件夹名称，value为该文件夹下所有图片的路径组成的list\n",
    "        return img_paths\n",
    "    \n",
    "    def __get_image(self,img_path,new_size=200):\n",
    "        def resize_img(image,new_size):\n",
    "            '''将image的长或宽中的最小值调整到new_size'''\n",
    "            h,w=image.shape[:2]\n",
    "            ratio=new_size/min(h,w)\n",
    "            return cv2.resize(image,(int(w*ratio),int(h*ratio)))\n",
    "        \n",
    "        image=cv2.imread(img_path)\n",
    "        return resize_img(image,new_size)\n",
    "    \n",
    "    def __img_sift_features(self,image):\n",
    "        '''\n",
    "        提取图片image中的Star特征的关键点，然后用SIFT特征提取器进行计算，\n",
    "        得到N行128列的矩阵，每幅图中提取的Star特征个数不一样，故而N不一样，\n",
    "        但是经过SIFT计算之后，特征的维度都变成128维。\n",
    "        返回该N行128列的矩阵\n",
    "        '''\n",
    "        keypoints=xfeatures2d.StarDetector_create().detect(image)\n",
    "        gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        _,feature_vectors=xfeatures2d.SIFT_create().compute(gray,keypoints)\n",
    "        return feature_vectors\n",
    "    \n",
    "    def __calc_imgs_features(self,img_path_list):\n",
    "        '''获取多张图片的特征矢量，这些特征矢量是合并到一起的，最终组成M行128列的矩阵，返回该矩阵.\n",
    "        此处的M是每张图片的特征矢量个数之和，即N1+N2+N3....'''\n",
    "        img_paths=list(itertools.chain(*img_path_list)) # 将多层list展开\n",
    "        feature_vectors=[]\n",
    "        [feature_vectors.extend(self.__img_sift_features(self.__get_image(img_path))) for img_path in img_paths]\n",
    "        return feature_vectors\n",
    "    \n",
    "    def __create_save_Cluster(self):\n",
    "        '''由于folders中含有大量图片，故而取一小部分（max_samples）图片来做K-means聚类。\n",
    "        '''\n",
    "        # 获取要进行聚类的小部分图片的路径\n",
    "        cluster_img_paths=[list(item.values())[0][:self.max_samples] for item in self.img_paths]\n",
    "        feature_vectors=self.__calc_imgs_features(cluster_img_paths)\n",
    "        cluster_model = KMeans(self.clusters_num,  # 建立聚类模型\n",
    "                        n_init=10,\n",
    "                        max_iter=10, tol=1.0)\n",
    "        cluster_model.fit(feature_vectors) # 对聚类模型进行训练\n",
    "        # 将聚类模型保存，以后就不需要再训练了。\n",
    "        with open(self.cluster_model_path,'wb+') as file:\n",
    "            pickle.dump(cluster_model,file)\n",
    "        print('cluster model is saved to {}.'.format(self.cluster_model_path))\n",
    "        return cluster_model\n",
    "    \n",
    "    def __map_feature_to_cluster(self,img_path):\n",
    "        '''从单张图片中提取Star特征矩阵（N行128列），\n",
    "        再将该特征矩阵通过K-means聚类算法映射到K个类别中，每一行特征映射到一个簇中，得到N个簇标号的向量，\n",
    "        统计每一个簇中出现的特征向量的个数，相当于统计词袋中某个单词出现的频次。\n",
    "        '''\n",
    "        img_feature_vectors=self.__img_sift_features(self.__get_image(img_path)) # N 行128列\n",
    "        cluster_labels=self.cluster_model.predict(img_feature_vectors) \n",
    "        # 计算这些特征在K个簇中的类别，得到N个数字，每个数字是0-31中的某一个，代表该Star特征属于哪一个簇\n",
    "        # eg [30 30 30  6 30 30 23 25 23 23 30 30 16 17 31 30 30 30  4 25]\n",
    "        \n",
    "        # 统计每个簇中特征的个数\n",
    "        vector_nums=np.zeros(self.clusters_num) # 32个元素\n",
    "        for num in cluster_labels:\n",
    "            vector_nums[num]+=1\n",
    "        \n",
    "        # 将特征个数归一化处理：得到百分比而非个数\n",
    "        sum_=sum(vector_nums)\n",
    "        return [vector_nums/sum_] if sum_>0 else [vector_nums] # 一行32列，32 个元素组成的list\n",
    "    \n",
    "    def __calc_imgs_clusters(self,img_path_list):\n",
    "        '''获取多张图片的视觉码本，将这些视觉码本组成一个P行32列的矩阵，P是图片张数，32是聚类的类别数。\n",
    "        返回该P行32列的矩阵'''\n",
    "        img_paths=list(itertools.chain(*img_path_list)) # 将多层list展开\n",
    "        code_books=[]\n",
    "        [code_books.extend(self.__map_feature_to_cluster(img_path)) for img_path in img_paths]\n",
    "        return code_books\n",
    "    \n",
    "    def __load_cluster_model(self):\n",
    "        '''从cluster_model_path中加载聚类模型，返回该模型，如果不存在或出错，则调用函数准备聚类模型'''\n",
    "        cluster_model=None\n",
    "        if os.path.exists(self.cluster_model_path):\n",
    "            try:\n",
    "                with open(self.cluster_model_path, 'rb') as f:\n",
    "                    cluster_model = pickle.load(f)\n",
    "            except:\n",
    "                pass\n",
    "        if cluster_model is None: \n",
    "            print('No valid model found, start to prepare model...')\n",
    "            cluster_model=self.__create_save_Cluster()\n",
    "        return cluster_model\n",
    "    \n",
    "    def get_img_code_book(self,img_path):\n",
    "        '''获取单张图片的视觉码本，即一行32列的list，每个元素都是对应特征出现的频率'''\n",
    "        return self.__map_feature_to_cluster(img_path)\n",
    "    def get_imgs_code_books(self,img_path_list):\n",
    "        '''获取多张图片的视觉码本，即P行32列的list，每个元素都是对应特征出现的频率'''\n",
    "        return self.__calc_imgs_clusters(img_path_list)\n",
    "    def get_all_img_code_books(self):\n",
    "        '''获取img_folder中所有图片的视觉码本'''\n",
    "        return self.__calc_imgs_clusters(self.all_img_paths)\n",
    "    def get_img_labels(self):\n",
    "        '''获取img_folder中所有图片对应的label，可以从文件夹名称中获取'''\n",
    "        img_paths=list(itertools.chain(*self.all_img_paths)) \n",
    "        return [img_path.rpartition('-')[0].rpartition('\\\\')[2] for img_path in img_paths]  \n",
    "    def prepare_dataset(self):\n",
    "        '''获取img_folder中所有图片的视觉码本和label，构成数据集'''\n",
    "        features=self.get_all_img_code_books()\n",
    "        labels=self.get_img_labels()\n",
    "        return np.c_[features,labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 33)\n",
      "[['0.0' '0.4' '0.0' '0.05' '0.0' '0.0' '0.0' '0.05' '0.0' '0.0' '0.0'\n",
      "  '0.1' '0.3' '0.0' '0.0' '0.0' '0.0' '0.05' '0.0' '0.0' '0.0' '0.0'\n",
      "  '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.0' '0.05' '0']\n",
      " ['0.0' '0.02702702702702703' '0.0' '0.0' '0.0' '0.0'\n",
      "  '0.02702702702702703' '0.02702702702702703' '0.0' '0.05405405405405406'\n",
      "  '0.08108108108108109' '0.05405405405405406' '0.40540540540540543' '0.0'\n",
      "  '0.0' '0.0' '0.0' '0.05405405405405406' '0.0' '0.0'\n",
      "  '0.05405405405405406' '0.0' '0.0' '0.0' '0.02702702702702703' '0.0'\n",
      "  '0.0' '0.0' '0.08108108108108109' '0.0' '0.10810810810810811' '0.0' '0']]\n"
     ]
    }
   ],
   "source": [
    "dataset=DataSet('E:\\PyProjects\\DataSet\\FireAI\\/training_images','./cluster_model1')\n",
    "# dataset.create_save_Cluster('./k_model1')\n",
    "# code_book=dataset.get_all_img_code_books()\n",
    "# print(np.array(code_book).shape)\n",
    "prepared=dataset.prepare_dataset()\n",
    "print(prepared.shape)\n",
    "print(prepared[:2]) # 检查没错，将准备好的数据集保存一下\n",
    "# img_list=[['E:\\\\PyProjects\\\\DataSet\\\\FireAI\\\\/training_images\\\\0-airplanes\\\\0001.jpg', \n",
    "#           'E:\\\\PyProjects\\\\DataSet\\\\FireAI\\\\/training_images\\\\0-airplanes\\\\0002.jpg', \n",
    "#           'E:\\\\PyProjects\\\\DataSet\\\\FireAI\\\\/training_images\\\\0-airplanes\\\\0003.jpg']]\n",
    "# code_book=dataset.get_imgs_code_books(img_list)\n",
    "\n",
    "df=pd.DataFrame(prepared)\n",
    "df.to_csv('./prepared_set.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 极端随机森林分类器\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "class CLF_Model:\n",
    "    \n",
    "    def __init__(self,n_estimators=100,max_depth=16):\n",
    "        self.model=ExtraTreesClassifier(n_estimators=n_estimators, \n",
    "                max_depth=max_depth, random_state=12)\n",
    "    def fit(self,train_X,train_y):\n",
    "        self.model.fit(train_X,train_y)\n",
    "    def predict(self,newSample_X):\n",
    "        return self.model.predict(newSample_X)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df=pd.read_csv('./prepared_set.txt',index_col=[0])\n",
    "dataset_X,dataset_y=dataset_df.iloc[:,:-1].values,dataset_df.iloc[:,-1].values\n",
    "model=CLF_Model()\n",
    "model.fit(dataset_X,dataset_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# 用训练好的model预测新图片，看看它属于哪一类\n",
    "new_img1='E:\\PyProjects\\DataSet\\FireAI/test0.jpg'\n",
    "img_code_book=dataset.get_img_code_book(new_img1)\n",
    "predicted=model.predict(img_code_book)\n",
    "print(predicted)\n",
    "\n",
    "new_img2='E:\\PyProjects\\DataSet\\FireAI/test1.jpg'\n",
    "img_code_book=dataset.get_img_code_book(new_img2)\n",
    "predicted=model.predict(img_code_book)\n",
    "print(predicted)\n",
    "\n",
    "new_img3='E:\\PyProjects\\DataSet\\FireAI/test2.jpg'\n",
    "img_code_book=dataset.get_img_code_book(new_img3)\n",
    "predicted=model.predict(img_code_book)\n",
    "print(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
